{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_url = \"https://ressources.data.sncf.com/api/records/1.0/search/\"\n",
    "dataset = \"objets-trouves-gares\"\n",
    "rows = -1\n",
    "sort = \"date\"\n",
    "start = 0\n",
    "facet=[\"date\", \"gc_obo_gare_origine_r_name\", \"gc_obo_type_c\"]\n",
    "refine=[\"date=2021\", \"gc_obo_gare_origine_r_name=Paris Gare du Nord\"]\n",
    "\n",
    "# concaténation de tous les paramètres\n",
    "params = f\"?dataset={dataset}&rows={rows}&sort={sort}&start={start}&facet={facet[0]}&facet={facet[1]}&facet={facet[2]}&refine.{refine[0]}&refine.{refine[1]}\"\n",
    "\n",
    "# construction de l'URL finale\n",
    "url = api_url + params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23-04-2022'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nom='23-04-2022,59596'\n",
    "nom[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(81632, 10)\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"concat.csv\")\n",
    "print(df.shape)\n",
    "dof=df.head()\n",
    "df['fields.date']=df['fields.date'].apply(lambda x : x [:10])\n",
    "# for i in dof.values:\n",
    "#     print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={\"fields.date\":\"date\"},inplace=True)\n",
    "df.rename(columns={\"fields.gc_obo_nature_c\":\"type\"},inplace=True)\n",
    "df.rename(columns={\"fields.gc_obo_gare_origine_r_name\":\"nom_gare\"},inplace=True)\n",
    "dif=df[['date','type','nom_gare']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'df.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcsv\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msqlite3\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mdf.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m      4\u001b[0m     reader \u001b[39m=\u001b[39m csv\u001b[39m.\u001b[39mreader(file)\n\u001b[1;32m      5\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m reader:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[1;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m     )\n\u001b[0;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'df.csv'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "with open('df.csv', 'r') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i in reader:\n",
    "        dati = i['date']\n",
    "        typo = i['type']\n",
    "        gara = i['nom_gare']\n",
    "        connexion = sqlite3.connect(\"bdd.db\")\n",
    "        curseur = connexion.cursor()\n",
    "        curseur.execute(\"\"\"\n",
    "            INSERT INTO objets_trouves (data,typo,nom_gare)\n",
    "            VALUES\n",
    "            ('{}','{}','{}')\n",
    "        \"\"\".format(dati, typo, gara))\n",
    "        connexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "near \"identité\": syntax error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m connexion \u001b[39m=\u001b[39m sqlite3\u001b[39m.\u001b[39mconnect(\u001b[39m\"\u001b[39m\u001b[39mbdd.db\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m curseur \u001b[39m=\u001b[39m connexion\u001b[39m.\u001b[39mcursor()\n\u001b[0;32m----> 7\u001b[0m curseur\u001b[39m.\u001b[39;49mexecute(\u001b[39m\"\"\"\u001b[39;49m\n\u001b[1;32m      8\u001b[0m \u001b[39m    INSERT INTO objets_trouves (data,typo,nom_gare)\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \u001b[39m    VALUES\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[39m    (\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m)\u001b[39;49m\n\u001b[1;32m     11\u001b[0m \u001b[39m\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(dati, typo, gara))\n\u001b[1;32m     12\u001b[0m connexion\u001b[39m.\u001b[39mcommit()\n",
      "\u001b[0;31mOperationalError\u001b[0m: near \"identité\": syntax error"
     ]
    }
   ],
   "source": [
    "for index, row in df.iterrows():\n",
    "    dati = row['date']\n",
    "    typo = row['type']\n",
    "    gara = row['nom_gare']\n",
    "    connexion = sqlite3.connect(\"bdd.db\")\n",
    "    curseur = connexion.cursor()\n",
    "    curseur.execute(\"\"\"\n",
    "        INSERT INTO objets_trouves (data,typo,nom_gare)\n",
    "        VALUES\n",
    "        ('{}','{}','{}')\n",
    "    \"\"\".format(dati, typo, gara))\n",
    "    connexion.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "conect= sqlite3.connect(\"bdd1.db\")\n",
    "#conversion du fichier csv en format sql, contenu dans la bdd \"bddeti.db\"\n",
    "\n",
    "dif.to_sql('objets_trouves', conect, if_exists='replace', index=False)\n",
    "\n",
    "conect.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def modifier_playlist(id:int, nveau_nom:str)->None:\n",
    "    connexion=sqlite3.connect('bddb.db')\n",
    "    curseur= connexion.cursor()\n",
    "    \n",
    "    curseur.execute(\"\"\"\n",
    "                    UPDATE gare\n",
    "                        SET nom = ?\n",
    "                        WHERE id= ?\n",
    "                 \n",
    "                        \"\"\", (nveau_nom, id))\n",
    "    \n",
    "    connexion.commit()\n",
    "    connexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "def modifier_playlist(nom_gare:str, nveau_nom:str)->None:\n",
    "    connexion=sqlite3.connect('bddb.db')\n",
    "    curseur= connexion.cursor()\n",
    "    \n",
    "    curseur.execute(\"\"\"\n",
    "                    UPDATE gare\n",
    "                        SET nom_gare = ?\n",
    "                        WHERE nom_gare= ?\n",
    "                 \n",
    "                        \"\"\", (nveau_nom, nom_gare))\n",
    "    \n",
    "    connexion.commit()\n",
    "    connexion.close()\n",
    "    \n",
    "modifier_playlist('paris est','93300618')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connexion=sqlite3.connect('bdd1.db')\n",
    "\n",
    "SELECT strftime('%Y-%W', date) AS week, COUNT(*) AS num_objects_found\n",
    "FROM objets_trouves\n",
    "WHERE date BETWEEN '2019-01-01' AND '2022-12-31'\n",
    "GROUP BY week\n",
    "ORDER BY week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite3 'bdd1.sqlite3'\n",
    "SELECT strftime('%Y-%W', date) AS week, COUNT(*) AS num_objects_found\n",
    "FROM objets_trouves\n",
    "WHERE date BETWEEN '2019-01-01' AND '2022-12-31'\n",
    "GROUP BY week\n",
    "ORDER BY week;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104869/2158327588.py:5: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_104869/2158327588.py:6: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "/tmp/ipykernel_104869/2158327588.py:7: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m daf\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mfields.gc_obo_type_c\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mtypo\u001b[39m\u001b[39m\"\u001b[39m},inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m daf\u001b[39m.\u001b[39mrename(columns\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mfields.gc_obo_gare_origine_r_name\u001b[39m\u001b[39m\"\u001b[39m:\u001b[39m\"\u001b[39m\u001b[39mgare\u001b[39m\u001b[39m\"\u001b[39m},inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m daf[\u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m daf[\u001b[39m'\u001b[39;49m\u001b[39mdate\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mstr\u001b[39m.\u001b[39mslice(stop\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv(\"concat.csv\")\n",
    "daf=df[['fields.gc_obo_type_c', 'fields.gc_obo_gare_origine_r_name','fields.date']]\n",
    "daf.rename(columns={\"fields.date\":\"data\"},inplace=True)\n",
    "daf.rename(columns={\"fields.gc_obo_type_c\":\"typo\"},inplace=True)\n",
    "daf.rename(columns={\"fields.gc_obo_gare_origine_r_name\":\"gare\"},inplace=True)\n",
    "daf['date'] = daf['date'].str.slice(stop=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('temp_paris.csv')\n",
    "daf = daf[['data', 'typo', 'gare']]\n",
    "daf['data']=daf['data'].apply(lambda x : x[:10])\n",
    "# Connexion à la base de données SQLite\n",
    "conn = sqlite3.connect('bddu.db')\n",
    "\n",
    "# Écriture du DataFrame dans une table SQL\n",
    "daf.to_sql('objets_trouves', conn, if_exists='append', index=False)\n",
    "\n",
    "# Fermeture de la connexion\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('bddt.db')\n",
    "\n",
    "# Écriture du DataFrame dans une table SQL\n",
    "# df.to_sql('meteo', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Fermeture de la connexion\n",
    "\n",
    "\n",
    "curseur = conn.cursor()\n",
    "\n",
    "\n",
    "for index, row in daf.iterrows():\n",
    "    curseur.execute(\"INSERT INTO objets_trouves (data,typo,gare) VALUES (?, ?,?)\", (row['data'], row['typo'],row['gare']))\n",
    "conn.commit()    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp_paris.csv')\n",
    "dif = pd.read_csv('frequentation.csv')\n",
    "# Connexion à la base de données SQLite\n",
    "conn = sqlite3.connect('bddt.db')\n",
    "\n",
    "# Écriture du DataFrame dans une table SQL\n",
    "# df.to_sql('meteo', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Fermeture de la connexion\n",
    "\n",
    "\n",
    "curseur = conn.cursor()\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    curseur.execute(\"INSERT INTO meteo (date, temperature) VALUES (?, ?)\", (row['date'], row['temperature_moyenne_°C']))\n",
    "for index, row in dif.iterrows():\n",
    "    curseur.execute(\"INSERT INTO gare (nom_gare, frequent_2019,frequent_2020,frequent_2021,frequent_2022) VALUES (?, ?,?,?,?)\", (row['gare'], row['frequent_2019'],row['frequent_2020'],row['frequent_2021'],row['frequent_2022']))\n",
    "conn.commit()    \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  nbre objets trouvés     week\n",
      "0   2019-01-07                  537  2019-01\n",
      "1   2019-01-14                  379  2019-02\n",
      "2   2019-01-21                  532  2019-03\n",
      "3   2019-01-28                  424  2019-04\n",
      "4   2019-02-04                  497  2019-05\n",
      "..         ...                  ...      ...\n",
      "204 2022-12-05                  480  2022-49\n",
      "205 2022-12-12                  463  2022-50\n",
      "206 2022-12-19                  471  2022-51\n",
      "207 2022-12-26                  455  2022-52\n",
      "208 2023-01-02                  350  2023-01\n",
      "\n",
      "[209 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104869/1299656157.py:4: SettingWithCopyWarning:\n",
      "\n",
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = daf[['date', 'type']]\n",
    "\n",
    "# Convertir la colonne date en format de date\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Définir la colonne date comme l'index du DataFrame\n",
    "df = df.set_index('date')\n",
    "\n",
    "# Sélectionner les données entre les dates '2019-01-01' et '2022-12-31'\n",
    "df = df.loc['2019-01-01':'2022-12-31']\n",
    "\n",
    "# Regrouper les données par semaine\n",
    "df = df.groupby(pd.Grouper(freq='W-MON')).count()\n",
    "\n",
    "# Renommer la colonne typo en num_objects_found\n",
    "df = df.rename(columns={'type': 'nbre objets trouvés'})\n",
    "\n",
    "# Réinitialiser l'index du DataFrame\n",
    "df = df.reset_index()\n",
    "\n",
    "# Extraire la semaine à partir de la colonne date\n",
    "df['week'] = df['date'].dt.strftime('%Y-%W')\n",
    "\n",
    "# Trier les données par ordre croissant de semaine\n",
    "df = df.sort_values('week')\n",
    "\n",
    "# Afficher les résultats\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexpress\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fig \u001b[39m=\u001b[39m px\u001b[39m.\u001b[39mhistogram(df, x\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweek\u001b[39m\u001b[39m\"\u001b[39m,y\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnbre objets trouvés\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m fig\u001b[39m.\u001b[39;49mshow()\n",
      "File \u001b[0;32m~/miniconda3/envs/machinelearning/lib/python3.10/site-packages/plotly/basedatatypes.py:3398\u001b[0m, in \u001b[0;36mBaseFigure.show\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3365\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3366\u001b[0m \u001b[39mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[1;32m   3367\u001b[0m \u001b[39mspecified by the renderer argument\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3394\u001b[0m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   3395\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3396\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mplotly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mio\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpio\u001b[39;00m\n\u001b[0;32m-> 3398\u001b[0m \u001b[39mreturn\u001b[39;00m pio\u001b[39m.\u001b[39;49mshow(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/machinelearning/lib/python3.10/site-packages/plotly/io/_renderers.py:396\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(fig, renderer, validate, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    392\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    393\u001b[0m         )\n\u001b[1;32m    395\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m nbformat \u001b[39mor\u001b[39;00m LooseVersion(nbformat\u001b[39m.\u001b[39m__version__) \u001b[39m<\u001b[39m LooseVersion(\u001b[39m\"\u001b[39m\u001b[39m4.2.0\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 396\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    397\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    398\u001b[0m         )\n\u001b[1;32m    400\u001b[0m     ipython_display\u001b[39m.\u001b[39mdisplay(bundle, raw\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    402\u001b[0m \u001b[39m# external renderers\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(df, x=\"week\",y=\"nbre objets trouvés\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n",
      "15\n",
      "17\n",
      "17\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "dataframe = np.random.randint(10, 20)\n",
    "dataframe\n",
    "\n",
    "for i in range (5):\n",
    "    df=np.random.randint(10, 20)\n",
    "    print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (main, Jan 11 2023, 15:21:40) [GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "abfbbb82e5734ddf6fe9d05af3064de704bc0f7110367d6a6ae63e383d8540d0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
